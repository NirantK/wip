{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index -qq\n",
    "import qdrant_client\n",
    "from datetime import datetime\n",
    "from llama_index import GPTVectorStoreIndex\n",
    "\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from pathlib import Path\n",
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.indices.postprocessor import (\n",
    "    FixedRecencyPostprocessor,\n",
    "    EmbeddingRecencyPostprocessor,\n",
    ")\n",
    "# load documents\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "Path.ls = lambda x: list(x.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(\n",
    "    # you can use :memory: mode for fast and light-weight experiments,\n",
    "    # it does not require to have Qdrant deployed anywhere\n",
    "    # but requires qdrant-client >= 1.1.1\n",
    "    location=\":memory:\"\n",
    "    # otherwise set Qdrant instance address with:\n",
    "    # uri=\"http://<host>:<port>\"\n",
    "    # set API KEY for Qdrant Cloud\n",
    "    # api_key=\"<qdrant-api-key>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/News_Category_Dataset_v3.json\", \"r\") as f:\n",
    "    data = [json.loads(k) for k in f.readlines()]\n",
    "    links = [k.pop(\"link\") for k in data]\n",
    "    authors = [k.pop(\"authors\") for k in data]\n",
    "    data = [\n",
    "        {\n",
    "            \"text\": f\"{k['headline']} under the category: {k['category']}\\n {k['short_description']}\",\n",
    "            \"date\": k[\"date\"],\n",
    "        }\n",
    "        for k in data\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dir = Path(\"../data/dump\").resolve()\n",
    "write_dir.mkdir(exist_ok=True, parents=True)\n",
    "for element in data:\n",
    "    file_path = write_dir / f\"{element['date']}.txt\"\n",
    "    with file_path.open(\"w\") as f:\n",
    "        f.write(element[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nirantk/Desktop/wip/data/dump/2014-12-11.txt 2012-01-28\n"
     ]
    }
   ],
   "source": [
    "print(write_dir.ls()[-1], file_path.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_metadata(file_name: str):\n",
    "    \"\"\"Get file metadata.\"\"\"\n",
    "    return {\"date\": Path(file_name).stem}\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=write_dir.ls(), file_metadata=get_file_metadata\n",
    ").load_data()\n",
    "\n",
    "# define service context (wrapper container around current classes)\n",
    "service_context = ServiceContext.from_defaults(chunk_size_limit=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(text='Mozambique Devises National Plan To End Child Marriage under the category: IMPACT\\n The institution affects nearly 1 in 2 girls in the African nation.', doc_id='637edd94-0f9d-4350-9223-3f6d89297046', embedding=None, doc_hash='36789ba23876ca964ccba0d40257174f4ecbd975def60266e18eda045ffe6c22', extra_info={'date': '2016-04-13'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use node parser in service context to parse into nodes\n",
    "nodes = service_context.node_parser.get_nodes_from_documents(documents)\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=\"huffpostnews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = GPTVectorStoreIndex.from_documents(documents, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Recency Postprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_postprocessor = FixedRecencyPostprocessor(service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_postprocessor_emb = EmbeddingRecencyPostprocessor(service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve top 10 most relevant nodes, then filter with Cohere Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.indices.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "cohere_rerank = CohereRerank(api_key=os.environ[\"COHERE_API_KEY\"], top_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[recency_postprocessor],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranking_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[cohere_rerank, recency_postprocessor],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[cohere_rerank, recency_postprocessor],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both: \n",
      "The current US President is Barack Obama.\n",
      "Recency: \n",
      "The current US President is Joe Biden.\n",
      "Reranking: \n",
      "The current US President is Barack Obama.\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is the current US President?\"\n",
    "\n",
    "response = query_engine.query(question)\n",
    "print(\"Both:\", response)\n",
    "response = recency_query_engine.query(question)\n",
    "print(\"Recency:\", response)\n",
    "response = reranking_query_engine.query(question)\n",
    "print(\"Reranking:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
